{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from PIL import Image  \n",
    "import gdown\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import json\n",
    "import traceback\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csf_file = \"/home/oleksandr/projects/upwork/esov-api/tmp/YouSov NFT randomization - NFT Randomization.csv\"\n",
    "rows = []\n",
    "with open(csf_file, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image_gdown(url, img_name):\n",
    "    if not url:\n",
    "        return None\n",
    "    if not os.path.exists(img_name):\n",
    "        print(f\"Downloading image {img_name} from {url}\")\n",
    "        gdown.download(url, img_name, quiet=False, fuzzy=True, use_cookies=True)\n",
    "    # else:\n",
    "    #     print(f\"Image {img_name} already exists\")\n",
    "    return Image.open(img_name)\n",
    "    \n",
    "\n",
    "def parser_row(prefix, out_fld, color_idx = None, img_idx = 3, filename=None):\n",
    "    print(\"Parsing rows with prefix:\", prefix)\n",
    "    rows_filtered = [r for r in rows if prefix in r[0]]\n",
    "    parsed = []\n",
    "    out_imgs_folder = f\"{out_fld}/{filename}\"\n",
    "    os.makedirs(out_imgs_folder, exist_ok=True)\n",
    "    for i, row in enumerate(rows_filtered):\n",
    "        img_name = f\"{out_imgs_folder}/{prefix}_{i}.png\"\n",
    "        parsed.append({\n",
    "            \"caption\": row[0],\n",
    "            \"probability\": float(row[1].replace(\"%\", \"\").replace(\",\",\".\"))/100,\n",
    "            \"name\": row[2],\n",
    "            \"gdrive_path\": row[img_idx],\n",
    "            \"color\": None if color_idx is None else row[color_idx],\n",
    "            \"pillow_img\": download_image_gdown(row[img_idx], img_name),\n",
    "        })\n",
    "    sum_probs = sum([r[\"probability\"] for r in parsed])\n",
    "    print(\"Sum of probabilities:\", sum_probs)\n",
    "    json_filename = f\"{out_fld}/{filename}.json\"\n",
    "    with open(json_filename, \"w\") as jsonfile:\n",
    "        jsonfile.write(json.dumps({\n",
    "            \"sum_probs\": sum_probs,\n",
    "            \"prefix\": prefix,\n",
    "            \"data\": [{\n",
    "                \"caption\": r[\"caption\"],\n",
    "                \"probability\": r[\"probability\"],\n",
    "                \"name\": r[\"name\"],\n",
    "                \"color\": r[\"color\"],\n",
    "                \"gdrive_path\": r[\"gdrive_path\"] if r[\"pillow_img\"] is not None else None,\n",
    "                \"img_path\": f\"{prefix}/{prefix}_{i}.png\" if r[\"pillow_img\"] is not None else None,\n",
    "            } for i, r in enumerate(parsed)]\n",
    "        }, indent=4))\n",
    "    return parsed\n",
    "\n",
    "folder_meta = \"/home/oleksandr/projects/upwork/esov-api/tmp/out_meta\"\n",
    "meta_L1 = parser_row(\"L1\", folder_meta, filename=\"L1\")\n",
    "meta_L2 = parser_row(\"[\", folder_meta, filename=\"L2\")\n",
    "meta_L3 = parser_row(\"L3\", folder_meta, color_idx=3, img_idx=4, filename=\"L3\")\n",
    "meta_L4 = parser_row(\"L4\", folder_meta, color_idx=3, img_idx=4, filename=\"L4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_L1 = json.load(open(f\"{folder_meta}/L1.json\"))\n",
    "loaded_L2 = json.load(open(f\"{folder_meta}/L2.json\"))\n",
    "loaded_L3 = json.load(open(f\"{folder_meta}/L3.json\"))\n",
    "loaded_L4 = json.load(open(f\"{folder_meta}/L4.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prob_map(meta):\n",
    "    # order meta by probability\n",
    "    print(\"===Loading prob map\")\n",
    "    meta_sorted = sorted(meta, key=lambda x: x[\"probability\"], reverse=False)\n",
    "    buckets = {}\n",
    "    buckets_count = 0\n",
    "    min_prob = meta_sorted[0][\"probability\"]\n",
    "    max_prob = meta_sorted[-1][\"probability\"]\n",
    "    sum_prob = 0\n",
    "    for i, p in enumerate(meta_sorted):\n",
    "        prob = p[\"probability\"]\n",
    "        p[\"idx\"] = i\n",
    "        if not prob in buckets:\n",
    "            buckets_count += 1\n",
    "            buckets[prob] = {\n",
    "                \"probability\": 0,\n",
    "                \"item_probability\": prob,\n",
    "                \"idx\": buckets_count,\n",
    "                \"items\": {}\n",
    "            }\n",
    "        bucket = buckets[prob]\n",
    "        sum_prob += prob\n",
    "        bucket[\"probability\"] += prob\n",
    "        bucket[\"lower_bound\"] = meta_sorted[i][\"probability\"]\n",
    "        bucket[\"upper_bound\"] = meta_sorted[i+1][\"probability\"] if i < len(meta_sorted)-1 else meta_sorted[i][\"probability\"]\n",
    "        bucket[\"items\"][i] = p\n",
    "\n",
    "    print(f\"Total buckets: {buckets_count}\")\n",
    "    print(f\"Sum of probabilities: {sum_prob}\")\n",
    "    print(f\"Min prob: {min_prob}, max prob: {max_prob}\")\n",
    "    print(\"===Prob map loaded\")\n",
    "    return {\n",
    "        \"buckets\": buckets,\n",
    "        \"sorted_meta\": meta_sorted,\n",
    "        \"min_prob\": min_prob,\n",
    "        \"max_prob\": max_prob,\n",
    "        \"sum_prob\": sum_prob,\n",
    "    }\n",
    "\n",
    "def get_random_item(buckets, random_val):\n",
    "    for prob in buckets.values():\n",
    "        if prob[\"lower_bound\"] <= random_val < prob[\"upper_bound\"]:\n",
    "            items = prob[\"items\"]\n",
    "            # get rand item\n",
    "            rand_item_idx = np.random.choice(list(items.keys()))\n",
    "            return items[rand_item_idx], prob\n",
    "        \n",
    "prob_map_L1 = load_prob_map(loaded_L1[\"data\"])\n",
    "prob_map_L2 = load_prob_map(loaded_L2[\"data\"])\n",
    "prob_map_L3 = load_prob_map(loaded_L3[\"data\"])\n",
    "prob_map_L4 = load_prob_map(loaded_L4[\"data\"])\n",
    "\n",
    "def benchmark(probmeta, times, label=\"\"):\n",
    "    try:\n",
    "        print(f\"Running benchmark {label}\")\n",
    "        buckets = probmeta[\"buckets\"]\n",
    "        sorted_meta = probmeta[\"sorted_meta\"]\n",
    "        min_prob = probmeta[\"min_prob\"]\n",
    "        max_prob = probmeta[\"max_prob\"]\n",
    "        hits = {s[\"idx\"]: 0 for s in sorted_meta}\n",
    "        print(f\"Min prob: {min_prob}, max prob: {max_prob}\")\n",
    "        for i in tqdm.tqdm(range(times)):\n",
    "            probabilities = [p[\"probability\"] for p in buckets.values()]\n",
    "            bucket_rolled = np.random.choice(list(buckets.values()), p=probabilities)\n",
    "            random_item = np.random.choice(list(bucket_rolled[\"items\"].values()))\n",
    "            hits[random_item[\"idx\"]] += 1\n",
    "        # validate that each bucket hit correctly by its probability\n",
    "        print(f\"Validation, rolling {times} times\")\n",
    "        total_deviation = 0\n",
    "        max_deviation = 0\n",
    "        min_deviation = 100\n",
    "        for p in sorted_meta:\n",
    "            prob = p[\"probability\"]\n",
    "            caption = p[\"caption\"]\n",
    "            total_hits = hits[p[\"idx\"]]\n",
    "            hits_prob = total_hits / times\n",
    "            deviation = (abs(prob-hits_prob)/prob)*100\n",
    "            total_deviation += deviation\n",
    "\n",
    "            if deviation > max_deviation:\n",
    "                max_deviation = deviation\n",
    "\n",
    "            if deviation < min_deviation:\n",
    "                min_deviation = deviation\n",
    "\n",
    "            print(f\"Item name: {caption}, Hits {total_hits}/{times}  Probability: {prob}, Real Probability: {hits_prob}, deviation %: {deviation}\")\n",
    "        print(f\"Min deviation %: {min_deviation}\")\n",
    "        print(f\"Max deviation %: {max_deviation}\")\n",
    "        print(f\"Average deviation %: {total_deviation/len(sorted_meta)}\")\n",
    "        print(\"Validation done\")\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "# benchmark(prob_map_L1, 100000)\n",
    "\n",
    "rolls = 1000000\n",
    "benchmark(prob_map_L1, rolls, \"L1\")\n",
    "benchmark(prob_map_L2, rolls, \"L2\")\n",
    "benchmark(prob_map_L3, rolls, \"L3\")\n",
    "benchmark(prob_map_L4, rolls, \"L4\")\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
