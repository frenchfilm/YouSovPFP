{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionImg2ImgPipeline, StableDiffusionControlNetImg2ImgPipeline, AutoencoderKL, ControlNetModel, DDIMScheduler\n",
    "from diffusers.utils import load_image\n",
    "import torch\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, sys\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropPILImage(im: Image, maxWidth=1024, maxHeight=1024, log = True):\n",
    "    imw, imh = im.size\n",
    "    ratioSource = imw / imh\n",
    "    ratioTarget = maxWidth / maxHeight\n",
    "\n",
    "    sourceIsLandScape = ratioSource > 1\n",
    "    targetIsLandScape = ratioTarget > 1\n",
    "\n",
    "    # resizing image proportionally\n",
    "    # so one of its side would be bigger than required, other eaual to required\n",
    "    # it will allow to crop it to required size from bigger side by leaving smaller side intact\n",
    "    # algorithm will check orientations and aspect ratios to do it correctly\n",
    "    # and avoid 'black bars' on sides\n",
    "\n",
    "    if sourceIsLandScape == targetIsLandScape:\n",
    "        log and print(\"cropPILImage: same orientation\")\n",
    "        if ratioSource < ratioTarget:\n",
    "            log and print(\"cropPILImage: source is wider\")\n",
    "            newWidth = maxWidth\n",
    "            newHeight = int(maxWidth / ratioSource)\n",
    "        else:\n",
    "            log and print(\"cropPILImage: source is taller\")\n",
    "            newHeight = maxHeight\n",
    "            newWidth = int(maxHeight * ratioSource)\n",
    "    elif sourceIsLandScape:\n",
    "        log and print(\"cropPILImage: source is wider\")\n",
    "        newHeight = maxHeight\n",
    "        newWidth = int(maxHeight * ratioSource)\n",
    "    else:\n",
    "        log and print(\"cropPILImage: source is taller\")\n",
    "        newWidth = maxWidth\n",
    "        newHeight = int(maxWidth / ratioSource)\n",
    "    \n",
    "    im = im.resize((newWidth, newHeight))\n",
    "        \n",
    "    # crop to max width and height evenly\n",
    "    imw, imh = im.size\n",
    "    deltax = (imw - maxWidth) // 2\n",
    "    deltay = (imh - maxHeight) // 2\n",
    "    im = im.crop((deltax, deltay, maxWidth + deltax, maxHeight + deltay))\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = os.path.abspath('')\n",
    "sys.path.insert(0, os.path.abspath(\n",
    "    os.path.join(os.path.dirname(__file__))))\n",
    "sys.path.insert(0, os.path.abspath(\n",
    "    os.path.join(os.path.dirname(__file__), '..')))\n",
    "sys.path.insert(0, os.path.abspath(\n",
    "    os.path.join(os.path.dirname(__file__), '../..')))\n",
    "from diffusion.common.lpw_processor import get_weighted_text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# controlnet = ControlNetModel.from_pretrained(\n",
    "#   \"Nacholmo/controlnet-qr-pattern-v2\",\n",
    "#   torch_dtype=torch.float16\n",
    "# ).to(\"cuda\")\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "  \"monster-labs/control_v1p_sd15_qrcode_monster\",\n",
    "  torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "# base_pipeline = StableDiffusionImg2ImgPipeline.from_single_file(\"/home/oleksandr/projects/upwork/esov-api/models/juggernaut_reborn.safetensors\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "base_pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    safety_checker=None,\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "vae = AutoencoderKL.from_single_file(\"/home/oleksandr/projects/upwork/esov-api/models/vae-ft-mse-840000-ema-pruned.ckpt\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "base_pipeline.vae = vae\n",
    "cn_pipeline = StableDiffusionControlNetImg2ImgPipeline(**base_pipeline.components, controlnet=controlnet).to(\"cuda\")\n",
    "\n",
    "\n",
    "# cn_pipeline = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(\n",
    "#     \"stabilityai/stable-diffusion-2-1\",\n",
    "#     safety_checker=None,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     controlnet=controlnet\n",
    "# ).to(\"cuda\")\n",
    "cn_pipeline.scheduler = DDIMScheduler.from_config(cn_pipeline.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrimg = Image.open(\"/home/oleksandr/projects/upwork/esov-api/tmp/qr/Piece 01.png\")\n",
    "style_fold = \"/home/oleksandr/projects/upwork/esov-api/tmp/qr/Reference - General Style\"\n",
    "img_fold = \"/home/oleksandr/projects/upwork/esov-api/tmp/qr/Style Scene 001\"\n",
    "\n",
    "def get_sorted_files(folder):\n",
    "    return sorted(os.listdir(folder), key=lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "style_imgs = []\n",
    "for file in get_sorted_files(style_fold):\n",
    "    style_img = Image.open(os.path.join(style_fold, file)).convert(\"RGB\")\n",
    "    style_imgs.append(cropPILImage(style_img, 1024, 1024))\n",
    "\n",
    "imgs = []\n",
    "for file in get_sorted_files(img_fold):\n",
    "    img = Image.open(os.path.join(img_fold, file)).convert(\"RGB\")\n",
    "    imgs.append(img)\n",
    "testqr = load_image(\"https://boofcv.org/images/3/35/Example_rendered_qrcode.png\")\n",
    "print(f\"QR Image size: {qrimg.size}\")\n",
    "print(f\"Style Image size: {style_imgs[0].size}\")\n",
    "print(f\"Image size: {imgs[0].size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay img[0] and qrimg with qrimg mask and 0.5 blend\n",
    "qr_img_resized = qrimg.resize(imgs[0].size).convert(\"RGBA\")\n",
    "to_blend = imgs[0].copy().convert(\"RGBA\")\n",
    "blended = Image.blend(to_blend, qr_img_resized, 0.7)\n",
    "pasted = imgs[0].copy()\n",
    "pasted.paste(blended, (0, 0), ImageOps.invert(qrimg.convert(\"L\")).resize(imgs[0].size))\n",
    "pasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=1024\n",
    "h=1024\n",
    "\n",
    "def resize_for_condition_image(input_image: Image, resolution: int):\n",
    "    input_image = input_image.convert(\"RGB\")\n",
    "    W, H = input_image.size\n",
    "    k = float(resolution) / min(H, W)\n",
    "    H *= k\n",
    "    W *= k\n",
    "    H = int(round(H / 64.0)) * 64\n",
    "    W = int(round(W / 64.0)) * 64\n",
    "    img = input_image.resize((W, H), resample=Image.LANCZOS)\n",
    "    return img\n",
    "\n",
    "prompt = \"Fantasy painting in the style of Frank Frazetta, a blue rat running in a spice storage room, Comic book cover art, Sword and sorcery\"\n",
    "# prompt = \"Fantasy painting in the style of Frank Frazetta\"\n",
    "negative_prompt = \"humans, swords, monsters\"\n",
    "\n",
    "prompt_embeds, negative_prompt_embeds = get_weighted_text_embeddings(cn_pipeline, prompt, negative_prompt, max_embeddings_multiples=3)\n",
    "\n",
    "generator = torch.Generator(device=\"cuda\").manual_seed(1)\n",
    "cn_pipeline(\n",
    "    prompt_embeds=prompt_embeds,\n",
    "    negative_prompt_embeds=negative_prompt_embeds,\n",
    "    \n",
    "    # image=resize_for_condition_image(pasted, w),\n",
    "    # control_image=resize_for_condition_image(ImageOps.invert(qrimg.convert(\"L\")).resize(imgs[0].size), w),\n",
    "    \n",
    "    image=resize_for_condition_image(imgs[0], w),\n",
    "    control_image=resize_for_condition_image(testqr, w),\n",
    "    # control_image=resize_for_condition_image(qrimg, w),\n",
    "    \n",
    "    strength=0.4,\n",
    "    guidance_scale=7,\n",
    "    num_inference_steps=60,\n",
    "    generator=generator,\n",
    "    w=w,\n",
    "    h=h,\n",
    "\n",
    "    controlnet_conditioning_scale=4.0,\n",
    "    control_guidance_start=0.0,\n",
    "    control_guidance_end=1.0,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_pipeline.unload_ip_adapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_pipeline.load_ip_adapter(\n",
    "            \"h94/IP-Adapter\", \n",
    "            subfolder=\"models\", \n",
    "            weight_name=\"ip-adapter-plus_sd15.safetensors\", \n",
    "            image_encoder_folder=\"models/image_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = qrimg.filter(ImageFilter.GaussianBlur(radius = 24)) \n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=1024\n",
    "h=1024\n",
    "generator = torch.Generator(device=\"cuda\").manual_seed(1)\n",
    "\n",
    "prompt = \"Fantasy painting in the style of Frank Frazetta, a blue rat running in a spice storage room, Sword and sorcery\"\n",
    "# prompt = \"Fantasy painting in the style of Frank Frazetta\"\n",
    "negative_prompt = \"humans, swords, monsters, (NSFW, nude, naked), bad proportions, undetailed, poorly drawn lines, illustration, 3d render, painting, unrealistic skin, ugly teeth, ugly pupil, (worst quality), (low quality), (normal quality), lowres, signature, watermark, username, cropped\"\n",
    "\n",
    "prompt_embeds, negative_prompt_embeds = get_weighted_text_embeddings(cn_pipeline, prompt, negative_prompt, max_embeddings_multiples=3)\n",
    "\n",
    "cn_pipeline.set_ip_adapter_scale(0.7)\n",
    "cn_pipeline(\n",
    "    prompt_embeds=prompt_embeds,\n",
    "    negative_prompt_embeds=negative_prompt_embeds,\n",
    "    \n",
    "    # image=resize_for_condition_image(pasted, w),\n",
    "    # control_image=resize_for_condition_image(ImageOps.invert(qrimg.convert(\"L\")).resize(imgs[0].size), w),\n",
    "    \n",
    "    ip_adapter_image=imgs[0],\n",
    "    image=resize_for_condition_image(imgs[0], w),\n",
    "    # control_image=resize_for_condition_image(testqr, w),\n",
    "    control_image=resize_for_condition_image(filtered, w),\n",
    "    \n",
    "    strength=0.99,\n",
    "    guidance_scale=15,\n",
    "    num_inference_steps=30,\n",
    "    generator=generator,\n",
    "    w=w,\n",
    "    h=h,\n",
    "\n",
    "    controlnet_conditioning_scale=2.0,\n",
    "    control_guidance_start=0.0,\n",
    "    control_guidance_end=1.0,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ready = []\n",
    "for img in imgs:\n",
    "    w=1024\n",
    "    h=1024\n",
    "    generator = torch.Generator(device=\"cuda\").manual_seed(1)\n",
    "\n",
    "    prompt = \"Fantasy painting in the style of Frank Frazetta, a blue rat running in a spice storage room, Comic book cover art, Sword and sorcery\"\n",
    "    # prompt = \"Fantasy painting in the style of Frank Frazetta\"\n",
    "    negative_prompt = \"humans, swords, monsters, (NSFW, nude, naked), bad proportions, undetailed, poorly drawn lines, illustration, 3d render, painting, unrealistic skin, ugly teeth, ugly pupil, (worst quality), (low quality), (normal quality), lowres, signature, watermark, username, cropped\"\n",
    "\n",
    "    prompt_embeds, negative_prompt_embeds = get_weighted_text_embeddings(cn_pipeline, prompt, negative_prompt, max_embeddings_multiples=3)\n",
    "\n",
    "    cn_pipeline.set_ip_adapter_scale(0.7)\n",
    "    imr = cn_pipeline(\n",
    "        prompt_embeds=prompt_embeds,\n",
    "        negative_prompt_embeds=negative_prompt_embeds,\n",
    "        \n",
    "        # image=resize_for_condition_image(pasted, w),\n",
    "        # control_image=resize_for_condition_image(ImageOps.invert(qrimg.convert(\"L\")).resize(imgs[0].size), w),\n",
    "        \n",
    "        ip_adapter_image=img,\n",
    "        image=resize_for_condition_image(img, w),\n",
    "        # control_image=resize_for_condition_image(testqr, w),\n",
    "        control_image=resize_for_condition_image(filtered, w),\n",
    "        \n",
    "        strength=0.9,\n",
    "        guidance_scale=15,\n",
    "        num_inference_steps=30,\n",
    "        generator=generator,\n",
    "        w=w,\n",
    "        h=h,\n",
    "\n",
    "        controlnet_conditioning_scale=2.0,\n",
    "        control_guidance_start=0.0,\n",
    "        control_guidance_end=1.0,\n",
    "    ).images[0]\n",
    "    imgs_ready.append(imr)\n",
    "\n",
    "vertical_two_grids = Image.new(\"RGB\", (2048, 1024*len(imgs)))\n",
    "for i, img in enumerate(imgs_ready):\n",
    "    vertical_two_grids.paste(imgs[i].resize((1024,1024)), (0, 1024*i))\n",
    "    vertical_two_grids.paste(imgs_ready[i], (1024, 1024*i))\n",
    "\n",
    "vertical_two_grids.save(\"/home/oleksandr/projects/upwork/esov-api/tmp/out/m1.jpg\")\n",
    "\n",
    "images_out_dir = \"/home/oleksandr/projects/upwork/esov-api/tmp/out/m\"\n",
    "os.makedirs(images_out_dir, exist_ok=True)\n",
    "for i, img in enumerate(imgs_ready):\n",
    "    img.save(f\"{images_out_dir}/{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_ready = []\n",
    "for img in style_imgs:\n",
    "    w=1024\n",
    "    h=1024\n",
    "    generator = torch.Generator(device=\"cuda\").manual_seed(1)\n",
    "\n",
    "    prompt = \"Fantasy painting in the style of Frank Frazetta\"\n",
    "    # prompt = \"Fantasy painting in the style of Frank Frazetta\"\n",
    "    negative_prompt = \"((((humans, swords, monsters, skeletons, naked woman)))) (NSFW, nude, naked), bad proportions, undetailed, poorly drawn lines, illustration, 3d render, painting, unrealistic skin, ugly teeth, ugly pupil, (worst quality), (low quality), (normal quality), lowres, signature, watermark, username, cropped\"\n",
    "\n",
    "    prompt_embeds, negative_prompt_embeds = get_weighted_text_embeddings(cn_pipeline, prompt, negative_prompt, max_embeddings_multiples=3)\n",
    "\n",
    "    cn_pipeline.set_ip_adapter_scale(0.7)\n",
    "    imr = cn_pipeline(\n",
    "        prompt_embeds=prompt_embeds,\n",
    "        negative_prompt_embeds=negative_prompt_embeds,\n",
    "        \n",
    "        # image=resize_for_condition_image(pasted, w),\n",
    "        # control_image=resize_for_condition_image(ImageOps.invert(qrimg.convert(\"L\")).resize(imgs[0].size), w),\n",
    "        \n",
    "        ip_adapter_image=img,\n",
    "        image=resize_for_condition_image(img, w),\n",
    "        # control_image=resize_for_condition_image(testqr, w),\n",
    "        control_image=resize_for_condition_image(filtered, w),\n",
    "        \n",
    "        strength=0.9,\n",
    "        guidance_scale=15,\n",
    "        num_inference_steps=30,\n",
    "        generator=generator,\n",
    "        w=w,\n",
    "        h=h,\n",
    "\n",
    "        controlnet_conditioning_scale=2.0,\n",
    "        control_guidance_start=0.0,\n",
    "        control_guidance_end=1.0,\n",
    "    ).images[0]\n",
    "    imgs_ready.append(imr)\n",
    "\n",
    "vertical_two_grids = Image.new(\"RGB\", (2048, 1024*len(imgs)))\n",
    "for i, img in enumerate(imgs_ready):\n",
    "    vertical_two_grids.paste(style_imgs[i], (0, 1024*i))\n",
    "    vertical_two_grids.paste(imgs_ready[i], (1024, 1024*i))\n",
    "\n",
    "vertical_two_grids.save(\"/home/oleksandr/projects/upwork/esov-api/tmp/out/s1.jpg\")\n",
    "\n",
    "images_out_dir = \"/home/oleksandr/projects/upwork/esov-api/tmp/out/s\"\n",
    "os.makedirs(images_out_dir, exist_ok=True)\n",
    "for i, img in enumerate(imgs_ready):\n",
    "    img.save(f\"{images_out_dir}/{i}.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantastic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
